{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"lexmachina-agent","text":"<p>A2A agent for Lex Machina</p>"},{"location":"docker-publishing/","title":"Docker Publishing Workflow","text":"<p>This document explains how the Docker image publishing workflow works for the Lex Machina Agent.</p>"},{"location":"docker-publishing/#overview","title":"Overview","text":"<p>The project automatically builds and publishes Docker images to GitHub Container Registry (<code>ghcr.io</code>) using GitHub Actions. Images are published on:</p> <ul> <li>Main branch pushes: Development images tagged with <code>main</code> and SHA-based tags</li> <li>Pull requests: Builds images for testing (not published)</li> <li>Git tags: Release images with version tags and <code>latest</code> tag</li> <li>Releases: Stable images with full version tagging</li> </ul>"},{"location":"docker-publishing/#workflows","title":"Workflows","text":""},{"location":"docker-publishing/#1-main-docker-workflow-githubworkflowsdocker-publishyml","title":"1. Main Docker Workflow (<code>.github/workflows/docker-publish.yml</code>)","text":"<p>This workflow handles Docker image building and publishing for most scenarios:</p> <ul> <li>Triggers: Push to main, PR creation/updates, Git tag pushes</li> <li>Platforms: Multi-platform builds for <code>linux/amd64</code> and <code>linux/arm64</code></li> <li>Caching: Uses GitHub Actions cache for faster builds</li> <li>Attestation: Generates build provenance attestations for security</li> </ul>"},{"location":"docker-publishing/#image-tags-generated","title":"Image Tags Generated:","text":"<ul> <li><code>main</code>: Latest development version from main branch</li> <li><code>main-&lt;sha&gt;</code>: Specific commit from main branch</li> <li><code>latest</code>: Latest stable release (only for main branch)</li> <li><code>v1.2.3</code>: Specific version tags from Git tags</li> <li><code>1.2</code>: Major.minor version</li> <li><code>1</code>: Major version only</li> </ul>"},{"location":"docker-publishing/#2-release-workflow-githubworkflowson-release-mainyml","title":"2. Release Workflow (<code>.github/workflows/on-release-main.yml</code>)","text":"<p>Enhanced release workflow that:</p> <ul> <li>Deploys documentation to GitHub Pages</li> <li>Publishes Docker images for releases</li> <li>Tags images as both <code>latest</code> and <code>stable</code></li> <li>Uses same multi-platform build setup</li> </ul>"},{"location":"docker-publishing/#image-repository","title":"Image Repository","text":"<p>Published images are available at:</p> <pre><code>ghcr.io/lexmachinainc/lexmachina-agent\n</code></pre>"},{"location":"docker-publishing/#security-features","title":"Security Features","text":"<ol> <li>Attestation: Build provenance is attached to images</li> <li>OIDC Token: Uses GitHub's OIDC for secure authentication</li> <li>Minimal Permissions: Workflows use least-privilege access</li> <li>Multi-platform: Supports both AMD64 and ARM64 architectures</li> </ol>"},{"location":"docker-publishing/#image-metadata","title":"Image Metadata","text":"<p>All images include OCI-compliant labels:</p> <ul> <li><code>org.opencontainers.image.title</code>: \"Lex Machina Agent\"</li> <li><code>org.opencontainers.image.description</code>: \"A2A agent for Lex Machina\"</li> <li><code>org.opencontainers.image.vendor</code>: \"Lex Machina Inc.\"</li> <li><code>org.opencontainers.image.licenses</code>: \"Apache-2.0\"</li> <li><code>org.opencontainers.image.source</code>: Repository URL</li> <li><code>org.opencontainers.image.created</code>: Build timestamp</li> <li><code>org.opencontainers.image.version</code>: Version from Git</li> <li><code>org.opencontainers.image.revision</code>: Git commit SHA</li> </ul>"},{"location":"docker-publishing/#using-published-images","title":"Using Published Images","text":""},{"location":"docker-publishing/#pull-latest-stable-release","title":"Pull Latest Stable Release","text":"<pre><code>docker pull ghcr.io/lexmachinainc/lexmachina-agent:latest\n</code></pre>"},{"location":"docker-publishing/#pull-development-version","title":"Pull Development Version","text":"<pre><code>docker pull ghcr.io/lexmachinainc/lexmachina-agent:main\n</code></pre>"},{"location":"docker-publishing/#pull-specific-version","title":"Pull Specific Version","text":"<pre><code>docker pull ghcr.io/lexmachinainc/lexmachina-agent:v1.0.0\n</code></pre>"},{"location":"docker-publishing/#run-with-environment-variables","title":"Run with Environment Variables","text":"<pre><code>docker run -d \\\n  --name lexmachina-agent \\\n  -p 10011:10011 \\\n  -e API_TOKEN=your_token \\\n  -e API_BASE_URL=https://law-api-poc.stage.lexmachina.com \\\n  ghcr.io/lexmachinainc/lexmachina-agent:latest\n</code></pre>"},{"location":"docker-publishing/#local-development","title":"Local Development","text":""},{"location":"docker-publishing/#using-docker-compose","title":"Using Docker Compose","text":"<pre><code># Copy and configure environment\ncp .env.example .env\n# Edit .env with your API credentials\n\n# Start the service\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f\n\n# Stop the service\ndocker-compose down\n</code></pre>"},{"location":"docker-publishing/#building-locally","title":"Building Locally","text":"<pre><code># Build the image\ndocker build -t lexmachina-agent .\n\n# Run locally built image\ndocker run -p 10011:10011 \\\n  -e API_TOKEN=your_token \\\n  lexmachina-agent\n</code></pre>"},{"location":"docker-publishing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"docker-publishing/#image-not-found","title":"Image Not Found","text":"<p>Ensure you're using the correct registry and repository name:</p> <pre><code>ghcr.io/lexmachinainc/lexmachina-agent\n</code></pre>"},{"location":"docker-publishing/#authentication-issues","title":"Authentication Issues","text":"<p>The images are public and don't require authentication to pull. If you encounter issues:</p> <ol> <li>Check your network connectivity</li> <li>Verify the tag exists: https://github.com/LexMachinaInc/lexmachina-agent/pkgs/container/lexmachina-agent</li> <li>Try pulling without specifying a tag to get latest</li> </ol>"},{"location":"docker-publishing/#build-failures","title":"Build Failures","text":"<p>If the workflow fails:</p> <ol> <li>Check the Actions tab for detailed error logs</li> <li>Verify Dockerfile syntax</li> <li>Ensure all dependencies in <code>uv.lock</code> are available</li> <li>Check for network issues during dependency installation</li> </ol>"},{"location":"docker-publishing/#maintenance","title":"Maintenance","text":""},{"location":"docker-publishing/#adding-new-build-arguments","title":"Adding New Build Arguments","text":"<p>To add new build arguments:</p> <ol> <li>Add <code>ARG</code> instructions to the Dockerfile</li> <li>Add corresponding <code>build-args</code> to both workflows</li> <li>Update the metadata extraction in workflows if needed</li> </ol>"},{"location":"docker-publishing/#changing-image-tags","title":"Changing Image Tags","text":"<p>To modify tagging strategy:</p> <ol> <li>Update the <code>tags:</code> section in the <code>docker/metadata-action</code> step</li> <li>Refer to the metadata action documentation for tag patterns</li> </ol>"},{"location":"docker-publishing/#platform-support","title":"Platform Support","text":"<p>To add or remove platforms:</p> <ol> <li>Modify the <code>platforms:</code> field in the build step</li> <li>Ensure base images support the target platforms</li> <li>Test builds on all target platforms</li> </ol>"},{"location":"modules/","title":"Python Modules (Developer)","text":"<p>Server application for the Lex Machina A2A agent proxy</p>"},{"location":"modules/#lexmachina_agent.agent_executor.APIAgentConfiguration","title":"<code>APIAgentConfiguration</code>","text":"<p>Configuration for the Lex Machina API Agent. It supports authentication via API token, OAuth2 client credentials, or delegation URL.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>class APIAgentConfiguration:\n    \"\"\"Configuration for the Lex Machina API Agent.\n    It supports authentication via API token, OAuth2 client credentials, or delegation URL.\"\"\"\n\n    def __init__(self) -&gt; None:\n        # Load configuration from environment variables\n        api_base_url = os.environ.get(\"API_BASE_URL\", \"https://law-api-poc.stage.lexmachina.com\")\n        token = os.environ.get(\"API_TOKEN\")\n        client_id = os.environ.get(\"CLIENT_ID\")\n        client_secret = os.environ.get(\"CLIENT_SECRET\")\n        delegation_url = os.environ.get(\"DELEGATION_URL\")\n\n        if all(v is None for v in [token, client_id, client_secret, delegation_url]):\n            raise MissingConfigurationError([\"API_TOKEN\", \"CLIENT_ID\", \"CLIENT_SECRET\", \"DELEGATION_URL\"])\n\n        if token:\n            logger.warning(\n                \"Using API_TOKEN for authentication. Consider using CLIENT_ID / CLIENT_SECRET, or DELEGATION_URL for better security.\"\n            )\n        if client_id is not None and client_secret is None:\n            raise RequiredConfigurationError(\"CLIENT_SECRET\")\n        if client_secret is not None and client_id is None:\n            raise RequiredConfigurationError(\"CLIENT_ID\")\n\n        self.api_base_url = api_base_url\n        self.token = token\n        self.client_id = client_id\n        self.client_secret = client_secret\n        self.delegation_url = delegation_url\n\n    @property\n    def is_using_delegation(self) -&gt; bool:\n        return self.delegation_url is not None\n\n    def build_agent(self) -&gt; \"LexMachinaAPIAgent\":\n        \"\"\"Constructs and returns a LexMachinaAPIAgent instance based on the configuration.\"\"\"\n        if self.token:\n            return LexMachinaAPIAgent(\n                api_base_url=self.api_base_url,\n                token=self.token,\n            )\n        elif self.client_id and self.client_secret:\n            data = {\n                \"grant_type\": \"client_credentials\",\n                \"client_id\": self.client_id,\n                \"client_secret\": self.client_secret,\n            }\n            token_url = f\"{self.api_base_url}/api/token\"\n            try:\n                resp = httpx.post(token_url, data=data, headers={\"Accept\": \"application/json\"})\n                resp.raise_for_status()\n                access_token = resp.json().get(\"access_token\")\n                if not access_token:\n                    logger.error(\"Token endpoint did not return access_token.\")\n                    raise ConfigurationError()\n                return LexMachinaAPIAgent(\n                    api_base_url=self.api_base_url,\n                    token=typing.cast(str, access_token),\n                )\n            except httpx.HTTPError:\n                logger.exception(\"OAuth2 token request failed.\")\n                raise\n        elif self.delegation_url:\n            # Implement delegation URL based authentication\n            raise NotImplementedError(\"Delegation URL authentication not implemented yet.\")\n        else:\n            raise ConfigurationError()  # This should not happen\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.APIAgentConfiguration.build_agent","title":"<code>build_agent()</code>","text":"<p>Constructs and returns a LexMachinaAPIAgent instance based on the configuration.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>def build_agent(self) -&gt; \"LexMachinaAPIAgent\":\n    \"\"\"Constructs and returns a LexMachinaAPIAgent instance based on the configuration.\"\"\"\n    if self.token:\n        return LexMachinaAPIAgent(\n            api_base_url=self.api_base_url,\n            token=self.token,\n        )\n    elif self.client_id and self.client_secret:\n        data = {\n            \"grant_type\": \"client_credentials\",\n            \"client_id\": self.client_id,\n            \"client_secret\": self.client_secret,\n        }\n        token_url = f\"{self.api_base_url}/api/token\"\n        try:\n            resp = httpx.post(token_url, data=data, headers={\"Accept\": \"application/json\"})\n            resp.raise_for_status()\n            access_token = resp.json().get(\"access_token\")\n            if not access_token:\n                logger.error(\"Token endpoint did not return access_token.\")\n                raise ConfigurationError()\n            return LexMachinaAPIAgent(\n                api_base_url=self.api_base_url,\n                token=typing.cast(str, access_token),\n            )\n        except httpx.HTTPError:\n            logger.exception(\"OAuth2 token request failed.\")\n            raise\n    elif self.delegation_url:\n        # Implement delegation URL based authentication\n        raise NotImplementedError(\"Delegation URL authentication not implemented yet.\")\n    else:\n        raise ConfigurationError()  # This should not happen\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.ConfigurationError","title":"<code>ConfigurationError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base class for configuration-related errors.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>class ConfigurationError(Exception):\n    \"\"\"Base class for configuration-related errors.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.args = (\"Invalid configuration\",)\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.LexMachinaAPIAgent","title":"<code>LexMachinaAPIAgent</code>","text":"<p>A stateful agent that manages communication with the external Prot\u00e9g\u00e9 in Lex Machina Agent API. It holds the HTTP client and authentication token.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>class LexMachinaAPIAgent:\n    \"\"\"\n    A stateful agent that manages communication with the external Prot\u00e9g\u00e9 in Lex Machina Agent API.\n    It holds the HTTP client and authentication token.\n    \"\"\"\n\n    def __init__(self, api_base_url: str, token: str):\n        self._api_base_url = api_base_url\n        self._headers = {\n            \"Authorization\": f\"Bearer {token}\",\n            \"Accept\": \"application/json\",\n        }\n        self._client = httpx.AsyncClient(base_url=self._api_base_url, headers=self._headers)\n        logger.info(\"LexMachinaAPIAgent initialized.\")\n\n    async def get_suggested_searches(self, query: str) -&gt; dict:\n        \"\"\"Calls the /search/ai_suggested endpoint.\"\"\"\n        try:\n            logger.info(f\"Fetching suggested searches for: '{query}'\")\n            response = await self._client.get(\"/search/ai_suggested\", params={\"q\": query})\n            response.raise_for_status()\n            return typing.cast(dict, response.json())\n        except httpx.HTTPStatusError as e:\n            logger.exception(\"API Error\")\n            return {\"error\": str(e)}\n\n    async def get_search_description(self, description_url: str) -&gt; dict:\n        \"\"\"Fetches the description for a single suggested search.\"\"\"\n        try:\n            logger.debug(f\"Fetching description from: {description_url}\")\n            response = await self._client.get(description_url)\n            response.raise_for_status()\n            return typing.cast(dict, response.json())\n        except httpx.HTTPStatusError as e:\n            logger.exception(\"API Error\")\n            return {\"error\": str(e)}\n\n    async def process_query(self, query: str) -&gt; dict:\n        \"\"\"\n        Main method to process a query, fetch suggestions, and enrich them in parallel.\n        \"\"\"\n        # 1. Get initial suggestions from the API agent\n        suggestions_response = await self.get_suggested_searches(query)\n\n        if \"error\" in suggestions_response or not suggestions_response.get(\"result\"):\n            logger.error(\"Failed to get initial suggestions.\")\n            return {\n                \"error\": \"Failed to get initial suggestions.\",\n                \"details\": suggestions_response,\n            }\n\n        # 2. Prepare for parallel enrichment\n        suggestions = suggestions_response[\"result\"]\n        enrichment_tasks = []\n        for suggestion in suggestions:\n            # For each suggestion, create a remote call to fetch its description\n            task = self.get_search_description(suggestion[\"description_url\"])\n            enrichment_tasks.append(task)\n\n        logger.debug(f\"Fetching {len(enrichment_tasks)} descriptions in parallel...\")\n\n        # 3. Execute all enrichment tasks concurrently and gather results\n        descriptions = await asyncio.gather(*enrichment_tasks)\n\n        # 4. Combine the original suggestions with their fetched descriptions\n        for suggestion, description_data in zip(suggestions, descriptions):\n            suggestion[\"enriched_description\"] = description_data\n\n        logger.debug(\"Query processing complete\")\n        return suggestions_response\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.LexMachinaAPIAgent.get_search_description","title":"<code>get_search_description(description_url)</code>  <code>async</code>","text":"<p>Fetches the description for a single suggested search.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>async def get_search_description(self, description_url: str) -&gt; dict:\n    \"\"\"Fetches the description for a single suggested search.\"\"\"\n    try:\n        logger.debug(f\"Fetching description from: {description_url}\")\n        response = await self._client.get(description_url)\n        response.raise_for_status()\n        return typing.cast(dict, response.json())\n    except httpx.HTTPStatusError as e:\n        logger.exception(\"API Error\")\n        return {\"error\": str(e)}\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.LexMachinaAPIAgent.get_suggested_searches","title":"<code>get_suggested_searches(query)</code>  <code>async</code>","text":"<p>Calls the /search/ai_suggested endpoint.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>async def get_suggested_searches(self, query: str) -&gt; dict:\n    \"\"\"Calls the /search/ai_suggested endpoint.\"\"\"\n    try:\n        logger.info(f\"Fetching suggested searches for: '{query}'\")\n        response = await self._client.get(\"/search/ai_suggested\", params={\"q\": query})\n        response.raise_for_status()\n        return typing.cast(dict, response.json())\n    except httpx.HTTPStatusError as e:\n        logger.exception(\"API Error\")\n        return {\"error\": str(e)}\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.LexMachinaAPIAgent.process_query","title":"<code>process_query(query)</code>  <code>async</code>","text":"<p>Main method to process a query, fetch suggestions, and enrich them in parallel.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>async def process_query(self, query: str) -&gt; dict:\n    \"\"\"\n    Main method to process a query, fetch suggestions, and enrich them in parallel.\n    \"\"\"\n    # 1. Get initial suggestions from the API agent\n    suggestions_response = await self.get_suggested_searches(query)\n\n    if \"error\" in suggestions_response or not suggestions_response.get(\"result\"):\n        logger.error(\"Failed to get initial suggestions.\")\n        return {\n            \"error\": \"Failed to get initial suggestions.\",\n            \"details\": suggestions_response,\n        }\n\n    # 2. Prepare for parallel enrichment\n    suggestions = suggestions_response[\"result\"]\n    enrichment_tasks = []\n    for suggestion in suggestions:\n        # For each suggestion, create a remote call to fetch its description\n        task = self.get_search_description(suggestion[\"description_url\"])\n        enrichment_tasks.append(task)\n\n    logger.debug(f\"Fetching {len(enrichment_tasks)} descriptions in parallel...\")\n\n    # 3. Execute all enrichment tasks concurrently and gather results\n    descriptions = await asyncio.gather(*enrichment_tasks)\n\n    # 4. Combine the original suggestions with their fetched descriptions\n    for suggestion, description_data in zip(suggestions, descriptions):\n        suggestion[\"enriched_description\"] = description_data\n\n    logger.debug(\"Query processing complete\")\n    return suggestions_response\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.LexmachinaAgentExecutor","title":"<code>LexmachinaAgentExecutor</code>","text":"<p>               Bases: <code>AgentExecutor</code></p> <p>AgentExecutor implementation for the Lex Machina agent.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>class LexmachinaAgentExecutor(AgentExecutor):\n    \"\"\"AgentExecutor implementation for the Lex Machina agent.\"\"\"\n\n    def __init__(self, config: APIAgentConfiguration) -&gt; None:\n        self.config = config\n\n    async def execute(\n        self,\n        context: RequestContext,\n        event_queue: EventQueue,\n    ) -&gt; None:\n        api = self.config.build_agent()\n        if context.task_id is None or context.context_id is None or context.message is None:\n            raise ServerError(error=InvalidParamsError(message=\"Missing task_id or context_id or message\"))\n        query = context.get_user_input()\n\n        results = await api.process_query(query)\n        parts = [Part(root=TextPart(text=str(results)))]\n        await event_queue.enqueue_event(\n            completed_task(\n                context.task_id,\n                context.context_id,\n                [new_artifact(parts, f\"suggestion_{context.task_id}\")],\n                [context.message],\n            )\n        )\n\n    async def cancel(self, request: RequestContext, event_queue: EventQueue) -&gt; None:\n        \"\"\"Cancellation is not supported.\"\"\"\n        raise ServerError(error=UnsupportedOperationError())\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.LexmachinaAgentExecutor.cancel","title":"<code>cancel(request, event_queue)</code>  <code>async</code>","text":"<p>Cancellation is not supported.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>async def cancel(self, request: RequestContext, event_queue: EventQueue) -&gt; None:\n    \"\"\"Cancellation is not supported.\"\"\"\n    raise ServerError(error=UnsupportedOperationError())\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.MissingConfigurationError","title":"<code>MissingConfigurationError</code>","text":"<p>               Bases: <code>ConfigurationError</code></p> <p>Raised when all configuration fields are missing.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>class MissingConfigurationError(ConfigurationError):\n    \"\"\"Raised when all configuration fields are missing.\"\"\"\n\n    def __init__(self, missing_fields: list[str]) -&gt; None:\n        self.args = (f\"Missing configuration values: {', '.join(missing_fields)}\",)\n</code></pre>"},{"location":"modules/#lexmachina_agent.agent_executor.RequiredConfigurationError","title":"<code>RequiredConfigurationError</code>","text":"<p>               Bases: <code>ConfigurationError</code></p> <p>Raised when a required configuration field is missing.</p> Source code in <code>src/lexmachina_agent/agent_executor.py</code> <pre><code>class RequiredConfigurationError(ConfigurationError):\n    \"\"\"Raised when a required configuration field is missing.\"\"\"\n\n    def __init__(self, field_name: str) -&gt; None:\n        self.args = (f\"Missing required configuration value: {field_name}\",)\n</code></pre>"},{"location":"modules/#lexmachina_agent.server.app","title":"<code>app()</code>","text":"<p>Create the Starlette ASGI application with the Lex Machina agent.</p> Source code in <code>src/lexmachina_agent/server.py</code> <pre><code>def app() -&gt; Starlette:\n    \"\"\"Create the Starlette ASGI application with the Lex Machina agent.\"\"\"\n    base_url = os.environ.get(\"BASE_URL\", \"http://localhost:10011\")\n    config = APIAgentConfiguration()\n    capabilities = AgentCapabilities(streaming=False)\n    skill = AgentSkill(\n        id=\"search_suggestions\",\n        name=\"Search Suggestions\",\n        description=\"\"\"This takes a natural language question or prompt and suggests options for searches.\n          You can ask for assistance in building searches and finding the analytics in Lex Machina you care about.\"\"\",\n        tags=[\"search\", \"suggestions\", \"analytics\", \"legal\"],\n        examples=[\n            \"What is the average time to resolution for contracts cases in SDNY in the last 3 months?\",\n            \"Time to trial in a Los Angeles County case before Judge Randy Rhodes?\",\n            \"Reversal rate for employment cases in the 5th circuit?\",\n            \"Patent cases that went to trial in the last 90 days\",\n            \"Cases before Judge Schofield that mention tortious interference\",\n            \"Has Warby Parker been sued in Texas?\",\n            \"Complaints in Torts cases that mention section 552\",\n            \"Pleadings that mention jurisprudence\",\n            \"Jury Verdicts filed in California in the last 5 years\",\n            \"How long do LA contracts cases before Judge Katherine Chilton take to get to trial?\",\n            \"What is Judge Lemelle's grant rate for transfer motions?\",\n            \"Which firms have the most experience arguing employment cases in N.D.Ill?\",\n        ],\n    )\n    agent_card = AgentCard(\n        name=\"Prot\u00e9g\u00e9 in Lex Machina Agent\",\n        description=\"Provide search suggestions based on user input.\",\n        url=base_url,\n        version=\"1.0.0\",\n        default_input_modes=[\"text\"],\n        default_output_modes=[\"application/json\"],\n        capabilities=capabilities,\n        skills=[skill],\n    )\n\n    request_handler = DefaultRequestHandler(\n        agent_executor=LexmachinaAgentExecutor(config=config),\n        task_store=InMemoryTaskStore(),\n    )\n\n    server = A2AStarletteApplication(agent_card=agent_card, http_handler=request_handler)\n    return server.build()\n</code></pre>"}]}